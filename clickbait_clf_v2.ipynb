{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickbait Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame, Series, read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database lenght : 59172 \n",
      "Clickbait ratio: 0.5118637193267086\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>titles</th>\n",
       "      <th>clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6574</td>\n",
       "      <td>6575</td>\n",
       "      <td>25 Things We Learned From Julia Louis-Dreyfus ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>39655</td>\n",
       "      <td>39656</td>\n",
       "      <td>John Brennan: Trump's 'Nazi Germany' tweet to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44513</td>\n",
       "      <td>44514</td>\n",
       "      <td>TruthRevolt.org: ISIS Stands For \"Israeli Secr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44205</td>\n",
       "      <td>44206</td>\n",
       "      <td>Peak Millennial? Cities Cant Assume a Continue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11106</td>\n",
       "      <td>11107</td>\n",
       "      <td>This Entire City Is Made Out Of Ice And It Wil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     id                                             titles  clickbait\n",
       "0   6574   6575  25 Things We Learned From Julia Louis-Dreyfus ...          1\n",
       "1  39655  39656  John Brennan: Trump's 'Nazi Germany' tweet to ...          0\n",
       "2  44513  44514  TruthRevolt.org: ISIS Stands For \"Israeli Secr...          0\n",
       "3  44205  44206  Peak Millennial? Cities Cant Assume a Continue...          0\n",
       "4  11106  11107  This Entire City Is Made Out Of Ice And It Wil...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = read_csv(\"clickBait_Data.csv\")\n",
    "titles_len = len(titles)\n",
    "clckbt_ratio = len(titles[titles[\"clickbait\"]==0])/titles_len\n",
    "print(\"Database lenght : {} \\nClickbait ratio: {}\".format(titles_len, clckbt_ratio))\n",
    "titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some clickbait headlines ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Things We Learned From Julia Louis-Dreyfus In 2014\n",
      "This Entire City Is Made Out Of Ice And It Will Blow Your Mind\n",
      "35 Gifts For the Wanderlust-Obsessed Person In Your Life\n",
      "This Dudes Theory On Life After Death Has Gone Viral After Blowing Everyones Mind\n",
      "Cat owners are more likely to be into BDSM than everyone else The list\n",
      "Howard Schultz Stepping Down as Starbucks CEO to Focus on Higher-End Shops\n",
      "This Brother Sent Relatives Christmas Cards Saying His Sister Was Dating Chief Keef\n",
      "ESPN Layoffs at Leading Edge of the Coming ‘Sports Bubble’\n",
      "You probably know to ask yourself, What do I want? Heres a way better question\n",
      "Jerry Brown: ‘We’re Not Going to Bring Stupid Lawsuits’ Against Trump Wall\n"
     ]
    }
   ],
   "source": [
    "for title in titles['titles'][titles['clickbait']==1][:10]:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing and Analysis\n",
    "\n",
    "Split into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(titles['titles'], titles[\"clickbait\"],\n",
    "                                                    test_size=.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Parse each headline string:\n",
    "\n",
    "- converts to lower-case,\n",
    "- expand contractions,\n",
    "- remove punctuation,\n",
    "- lemmatize words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from contractions import contractions_dict\n",
    "from nltk import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import contractions\n",
    "import string\n",
    "\n",
    "_lem = WordNetLemmatizer()\n",
    "contractions_set = set(contr.lower() for contr in contractions_dict)\n",
    "\n",
    "\n",
    "def remove_contractions(string):\n",
    "    string = string.lower()\n",
    "    contr_num = sum(1 for contr in contractions_set if contr in string)\n",
    "    parsed_string = ' '.join(contractions.fix(word) for word in string.split())\n",
    "    return parsed_string, contr_num\n",
    "\n",
    "\n",
    "def lemmatise_sentence(sentence):\n",
    "    \n",
    "    # remove contarctions and convert to lower case\n",
    "    sentence, contr_num = remove_contractions(sentence.lower())\n",
    "    \n",
    "    # remove punctuation\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation+'’‘'))  \n",
    "    \n",
    "    # lemmatize words\n",
    "    lemm_str = \"\"\n",
    "    for word, tag in pos_tag(word_tokenize(sentence.lower())):\n",
    "        if tag.startswith('NN'):\n",
    "            word_1 = word \n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            word_1 = word\n",
    "            pos = 'v'\n",
    "        elif tag.startswith('CD'):\n",
    "            word_1 = 'NUM'\n",
    "            pos = 'a'\n",
    "        else:\n",
    "            word_1 = word\n",
    "            pos = 'a'\n",
    "        lemm_str += ' '+_lem.lemmatize(word_1, pos)\n",
    "    \n",
    "    return lemm_str, contr_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a class that parse the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ParseString(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self = True\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_prep, contr_list = [], []\n",
    "        for string in X:\n",
    "            lemm_str, contr_num = lemmatise_sentence(string)\n",
    "            X_prep.append(lemm_str)\n",
    "            contr_list.append(contr_num)\n",
    "        return DataFrame({\"headline\": X_prep, \"contr num\":contr_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_prep = ParseString().fit_transform(X=X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generate the vocabulary__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')    # shut up bs4 URL warning\n",
    "\n",
    "\n",
    "def make_vocabulary(X, length, rm_words=False, to_del_words_list=None):\n",
    "    vectorizer = CountVectorizer(max_features=length)\n",
    "    vectorizer.fit(X)\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    if rm_words:\n",
    "        for word in to_del_words_list:\n",
    "            if word in vocab:\n",
    "                vocab.remove(word)\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def save_vocabulary(words_list, txt_file):\n",
    "    file = open(txt_file, 'w+')\n",
    "    for word in words_list:\n",
    "            file.write(str(key)+'\\n')\n",
    "    file.close()\n",
    "    \n",
    "    print('Vocabulary stored in \"{}\"'.format(txt_file))\n",
    "    \n",
    "\n",
    "def load_vocabulary(length, txt_file, to_del=None):\n",
    "    file = open(txt_file, 'r')\n",
    "    vocab = np.array([file.readline().rstrip().lower() for line in range(length)])\n",
    "    file.close()\n",
    "    print('Dictionary loaded.')\n",
    "    return vocab\n",
    "    \n",
    "\n",
    "to_del = ['trump','donald','christmas','obama','president','america','harry','russian','russia','china',\n",
    "          'american']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate __3 different vocabnularies__: \n",
    "- common words in all titles\n",
    "- common words in clckbt titles\n",
    "- common words in non-clckbait titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_clckb = X_train_prep.headline.values[y_train==1]\n",
    "X_train_noclckbt = X_train_prep.headline.values[y_train==0]\n",
    "\n",
    "full_vocab = make_vocabulary(X_train_prep.headline, length=20)\n",
    "clckbt_vocab = make_vocabulary(X_train_clckb, length=21, rm_words=True, to_del_words_list=to_del)\n",
    "no_clckbt_vocab = make_vocabulary(X_train_noclckbt, length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 most common clckbt and no_clckbt words (NB: in alphabetical order!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>No Clickbait</td>\n",
       "      <td>after</td>\n",
       "      <td>and</td>\n",
       "      <td>as</td>\n",
       "      <td>at</td>\n",
       "      <td>be</td>\n",
       "      <td>by</td>\n",
       "      <td>for</td>\n",
       "      <td>from</td>\n",
       "      <td>have</td>\n",
       "      <td>in</td>\n",
       "      <td>new</td>\n",
       "      <td>not</td>\n",
       "      <td>num</td>\n",
       "      <td>of</td>\n",
       "      <td>on</td>\n",
       "      <td>say</td>\n",
       "      <td>the</td>\n",
       "      <td>to</td>\n",
       "      <td>trump</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Clickbait</td>\n",
       "      <td>and</td>\n",
       "      <td>be</td>\n",
       "      <td>do</td>\n",
       "      <td>for</td>\n",
       "      <td>have</td>\n",
       "      <td>in</td>\n",
       "      <td>it</td>\n",
       "      <td>not</td>\n",
       "      <td>num</td>\n",
       "      <td>of</td>\n",
       "      <td>on</td>\n",
       "      <td>that</td>\n",
       "      <td>the</td>\n",
       "      <td>this</td>\n",
       "      <td>to</td>\n",
       "      <td>what</td>\n",
       "      <td>will</td>\n",
       "      <td>with</td>\n",
       "      <td>you</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Full</td>\n",
       "      <td>and</td>\n",
       "      <td>at</td>\n",
       "      <td>be</td>\n",
       "      <td>do</td>\n",
       "      <td>for</td>\n",
       "      <td>have</td>\n",
       "      <td>in</td>\n",
       "      <td>it</td>\n",
       "      <td>not</td>\n",
       "      <td>num</td>\n",
       "      <td>of</td>\n",
       "      <td>on</td>\n",
       "      <td>that</td>\n",
       "      <td>the</td>\n",
       "      <td>this</td>\n",
       "      <td>to</td>\n",
       "      <td>trump</td>\n",
       "      <td>will</td>\n",
       "      <td>with</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0    1   2    3     4     5    6     7     8    9   10  \\\n",
       "No Clickbait  after  and  as   at    be    by  for  from  have   in  new   \n",
       "Clickbait       and   be  do  for  have    in   it   not   num   of   on   \n",
       "Full            and   at  be   do   for  have   in    it   not  num   of   \n",
       "\n",
       "                11    12    13    14    15     16    17     18    19  \n",
       "No Clickbait   not   num    of    on   say    the    to  trump  with  \n",
       "Clickbait     that   the  this    to  what   will  with    you  your  \n",
       "Full            on  that   the  this    to  trump  will   with   you  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = DataFrame({'No Clickbait': no_clckbt_vocab[:20], \n",
    "                          'Clickbait': clckbt_vocab[:20], \n",
    "                          'Full': full_vocab[:20]})\n",
    "common_words.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the Pipeline\n",
    "\n",
    "Generate features array. Features: \n",
    "- 200 most common clckbt words\n",
    "- title length (in words)\n",
    "- stopwords ratio\n",
    "- contractions ratio\n",
    "- title starts with cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded.\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# make bag of words\n",
    "vocab = load_vocabulary(200, 'vocabularies/lem_clckbt_words.txt')\n",
    "\n",
    "\n",
    "\n",
    "class PreProcess(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.vectorizer = CountVectorizer(vocabulary=self.vocabulary)\n",
    "        self.stopwords_set = set(stopwords.words('english'))\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # bag of words\n",
    "        X_bag = self.vectorizer.transform(X.headline)\n",
    "        # meta data\n",
    "        meta_arr = []\n",
    "        for i in range(len(X)):\n",
    "            d = Counter(X.headline.iloc[i].split())\n",
    "            num_flag = 1 if list(d)[0]=='NUM' else 0\n",
    "            n_of_words = sum(d.values())\n",
    "            contr_r = X['contr num'].iloc[i]/n_of_words\n",
    "            stop_r = sum(d[key] for key in set(d.keys())&self.stopwords_set) / n_of_words\n",
    "            meta_arr.append([num_flag, contr_r, stop_r, n_of_words])\n",
    "        meta_arr = coo_matrix(meta_arr)\n",
    "        return hstack([X_bag, meta_arr])\n",
    "\n",
    "    \n",
    "    \n",
    "full_pipeline = Pipeline([\n",
    "    (\"parse text\", ParseString()),\n",
    "    (\"gen features\", PreProcess(vocabulary=vocab))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47928, 204)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prep = full_pipeline.fit_transform(X_train)\n",
    "X_train_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mini = X_train_prep.toarray()[:1000]\n",
    "y_train_mini = y_train[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train some classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, make_scorer\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Train Naive Bayes on only features words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.688\n",
      "precision: 0.735\n",
      "recall: 0.592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from utilities import print_scores\n",
    "\n",
    "mnb_clf = MultinomialNB()\n",
    "\n",
    "mnb_clf_cv = cross_validate(mnb_clf, X_train_mini[:,:200], y_train_mini, cv=5, scoring=scorers, n_jobs=5)\n",
    "print_scores(mnb_clf_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.721\n",
      "precision: 0.766\n",
      "recall: 0.617\n"
     ]
    }
   ],
   "source": [
    "mnb_clf_cv = cross_validate(mnb_clf, X_train_prep.toarray()[:,:200], y_train, cv=5, scoring=scorers, n_jobs=5)\n",
    "print_scores(mnb_clf_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_clf.fit(X_train_prep.toarray()[:,:200], y_train)\n",
    "probabilities = mnb_clf.predict_proba(X_train_prep.toarray()[:,:200])[:, 1]\n",
    "probabilities = probabilities.reshape((len(probabilities), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train Random Forest on Naive Bayes probabilities and non-word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_forest = np.concatenate([probabilities, X_train_prep.toarray()[:, 200:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.697\n",
      "precision: 0.717\n",
      "recall: 0.652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from utilities import print_scores\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "forest_cv = cross_validate(forest_clf, X_train_forest[:1000], y_train_mini, cv=5, scoring=scorers, n_jobs=-1)\n",
    "print_scores(forest_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 367 tasks      | elapsed:   21.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.732\n",
      "Best params: {'max_depth': 4.367870584636595, 'n_estimators': 55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   28.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_distrib = {\"n_estimators\": list(range(1,500)), \"max_depth\": reciprocal(2,100)}\n",
    "\n",
    "rnd_srch_forest = RandomizedSearchCV(forest_clf, param_distributions=param_distrib,\n",
    "                                     cv=5, scoring='accuracy', random_state=42,\n",
    "                                     n_iter=100, verbose=5, n_jobs=-1)\n",
    "\n",
    "rnd_srch_forest.fit(X_train_forest[:1000], y_train_mini)\n",
    "\n",
    "print('Best score: %.3f' % rnd_srch_forest.best_score_)\n",
    "print('Best params:', rnd_srch_forest.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.736\n",
      "precision: 0.813\n",
      "recall: 0.596\n"
     ]
    }
   ],
   "source": [
    "forest_clf = rnd_srch_forest.best_estimator_\n",
    "\n",
    "forest_cv = cross_validate(forest_clf, X_train_forest, y_train, cv=5, scoring=scorers, n_jobs=5)\n",
    "print_scores(forest_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Train SVM on Naive Bayes probabilities and non-word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.731\n",
      "precision: 0.801\n",
      "recall: 0.616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "svc_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "svc_cv = cross_validate(svc_clf, X_train_forest[:1000], y_train_mini, cv=5, scoring=scorers, n_jobs=-1)\n",
    "print_scores(svc_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 416 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1316 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4196 tasks      | elapsed:   14.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.734\n",
      "Best params: {'svm__C': 9.46086466149087, 'svm__gamma': 0.008532209584895145, 'svm__kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:   17.6s finished\n"
     ]
    }
   ],
   "source": [
    "param_distrib = {'svm__kernel': ['rbf', 'poly'],\n",
    "                 'svm__C': uniform(1,20),\n",
    "                 'svm__gamma': reciprocal(.0001, .1),\n",
    "                }\n",
    "                 \n",
    "\n",
    "rnd_srch_svc = RandomizedSearchCV(svc_clf, param_distributions=param_distrib,\n",
    "                                  cv=5, scoring='accuracy', n_iter=1000, verbose=5, n_jobs=-1)\n",
    "\n",
    "rnd_srch_svc.fit(X_train_forest[:1000], y_train_mini)\n",
    "\n",
    "print('Best score: %.3f' % rnd_srch_svc.best_score_)\n",
    "print('Best params:', rnd_srch_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.733\n",
      "precision: 0.826\n",
      "recall: 0.573\n"
     ]
    }
   ],
   "source": [
    "svc_clf = rnd_srch_svc.best_estimator_\n",
    "\n",
    "svc_clf_cv = cross_validate(svc_clf, X_train_forest, y_train, cv=5, scoring=scorers, n_jobs=5)\n",
    "print_scores(svc_clf_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Train naive Random Forest on all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.684\n",
      "precision: 0.715\n",
      "recall: 0.618\n"
     ]
    }
   ],
   "source": [
    "forest_clf_v1 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "forest_cv_v1 = cross_validate(forest_clf_v1, X_train_mini, y_train_mini, cv=5, scoring=scorers, n_jobs=-1)\n",
    "print_scores(forest_cv_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   30.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.728\n",
      "Best params: {'max_depth': 51.918851006225275, 'n_estimators': 294}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param_distrib = {\"n_estimators\": list(range(1,500)), \"max_depth\": reciprocal(2,100)}\n",
    "\n",
    "rnd_srch_forest_v1 = RandomizedSearchCV(forest_clf_v1, param_distributions=param_distrib,\n",
    "                                     cv=5, scoring='accuracy', random_state=42,\n",
    "                                     n_iter=100, verbose=5, n_jobs=-1)\n",
    "\n",
    "rnd_srch_forest_v1.fit(X_train_mini, y_train_mini)\n",
    "\n",
    "print('Best score: %.3f' % rnd_srch_forest_v1.best_score_)\n",
    "print('Best params:', rnd_srch_forest_v1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.805\n",
      "precision: 0.871\n",
      "recall: 0.705\n"
     ]
    }
   ],
   "source": [
    "forest_clf_v1 = rnd_srch_forest_v1.best_estimator_\n",
    "\n",
    "forest_cv_v1 = cross_validate(forest_clf_v1, X_train_prep, y_train, cv=5, scoring=scorers, n_jobs=5)\n",
    "print_scores(forest_cv_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Train naive SVM on all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_v1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "svc_cv_v1 = cross_validate(svc_clf_v1, X_train_mini, y_train_mini, cv=5, scoring=scorers, n_jobs=-1)\n",
    "print_scores(svc_cv_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distrib = {'svm__kernel': ['rbf', 'poly'],\n",
    "                 'svm__C': uniform(1,20),\n",
    "                 'svm__gamma': reciprocal(.0001, .1),\n",
    "                }\n",
    "\n",
    "rnd_srch_svc_v1 = RandomizedSearchCV(svc_clf_v1, param_distributions=param_distrib,\n",
    "                                  cv=5, scoring='accuracy', n_iter=100, verbose=5, n_jobs=-1)\n",
    "\n",
    "rnd_srch_svc_v1.fit(X_train_mini, y_train_mini)\n",
    "\n",
    "print('Best score: %.3f' % rnd_srch_svc_v1.best_score_)\n",
    "print('Best params:', rnd_srch_svc_v1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_v1 = rnd_srch_svc_v1.best_estimator_\n",
    "\n",
    "svc_clf_cv_v1 = cross_validate(svc_clf_v1, X_train_prep.toarray(), y_train, cv=5, scoring=scorers, n_jobs=5)\n",
    "print_scores(svc_clf_cv_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Test on Validation set\n",
    "\n",
    "Evaluate the three classifiers we've built on the Validation set to see which performs better\n",
    "\n",
    "### Prepare titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_prep = full_pipeline.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = mnb_clf.predict(X_val_prep.toarray()[:,:200])\n",
    "\n",
    "print('Score on the test set: %.3f' % accuracy_score(y_val, y_val_pred))\n",
    "print('Precision: %.3f' % precision_score(y_val, y_val_pred))\n",
    "print('Recall: %.3f' % recall_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_proba = mnb_clf.predict_proba(X_val_prep.toarray()[:,:200])[:,1]\n",
    "y_val_proba = y_val_proba.reshape((len(y_val), 1))\n",
    "X_val_forest = np.concatenate([y_val_proba, X_val_prep.toarray()[:, 200:]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf.fit(X_train_forest, y_train)\n",
    "y_val_pred = forest_clf.predict(X_val_forest)\n",
    "\n",
    "print('Score on the test set: %.3f' % accuracy_score(y_val, y_val_pred))\n",
    "print('Precision: %.3f' % precision_score(y_val, y_val_pred))\n",
    "print('Recall: %.3f' % recall_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf.fit(X_train_forest, y_train)\n",
    "y_val_pred = svc_clf.predict(X_val_forest)\n",
    "\n",
    "print('Score on the test set: %.3f' % accuracy_score(y_val, y_val_pred))\n",
    "print('Precision: %.3f' % precision_score(y_val, y_val_pred))\n",
    "print('Recall: %.3f' % recall_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on the test set: 0.818\n",
      "Precision: 0.882\n",
      "Recall: 0.720\n"
     ]
    }
   ],
   "source": [
    "forest_clf_v1.fit(X_train_prep, y_train)\n",
    "y_val_pred = forest_clf_v1.predict(X_val_prep)\n",
    "\n",
    "print('Score on the test set: %.3f' % accuracy_score(y_val, y_val_pred))\n",
    "print('Precision: %.3f' % precision_score(y_val, y_val_pred))\n",
    "print('Recall: %.3f' % recall_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Final evaluation on the Test Set\n",
    "\n",
    "Choose the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on the test set: 0.824\n",
      "Precision: 0.894\n",
      "Recall: 0.731\n"
     ]
    }
   ],
   "source": [
    "X_test_prep = full_pipeline.transform(X_test)\n",
    "y_test_pred = forest_clf_v1.predict(X_test_prep)\n",
    "\n",
    "print('Score on the test set: %.3f' % accuracy_score(y_test, y_test_pred))\n",
    "print('Precision: %.3f' % precision_score(y_test, y_test_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 7. Export the model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "filename = 'clickbait_classifier_v2.joblib'\n",
    "#dump(forest_clf_v1, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
